# -*- coding: utf-8 -*-
"""Input output pair

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LFj4fJBPhSqplgZTePan5FX9g_YhxdIT

# BYTE PAIR TOKENIZATION
"""

! pip3 install tiktoken

import importlib
import tiktoken
print(importlib.metadata.version("tiktoken"))

tokenizer=tiktoken.get_encoding("gpt2")

text=(
    "Hello ,do you know who I am I am saksham <?endoftext|> "
    "From gwalior ,Ya! from gwalior"
)
integers=tokenizer.encode(text,allowed_special={"<|endoftext|>"})
print(integers)

strings=tokenizer.decode(integers)
print(strings)

print(tokenizer.decode([3415]))

with open("the-verdict.txt","r") as f:
  raw_text=f.read()
enc_text=tokenizer.encode(raw_text)
print(len(enc_text)),enc_text

enc_sample=enc_text[50:]

context_size=4
x=enc_sample[:context_size]
y=enc_sample[1:context_size+1]
x,y

for i in range(1,context_size+1):
  context=enc_sample[:i]
  desired=enc_sample[i]
  print(context,"--->",desired)

from torch.utils.data import Dataset,DataLoader
class GPT(Dataset):
  def __init__(self,txt,tokenizer,max_length,stride):
    self.input_ids=[]
    self.target_ids=[]
    token_ids=tokenizer.encode(txt,allowed_special={"<|endoftext|>"})
    for i in range(0,len(token_ids)-max_length,stride):
      input_chunk=token_ids[i:i+max_length]
      target_chunk=token_ids[i+1:i+max_length+1]
      self.input_ids.append(torch.tensor(input_chunk))
      self.target_ids.append(torch.tensor(target_chunk))
  def __len__(self):
    return len(self.input_ids)
  def  __getitem__(self,idx):
    return self.input_ids[idx],self.target_ids[idx]

def create_dataloader(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):
  tokenizer=tiktoken.get_encoding("gpt2")
  dataset=GPT(txt,tokenizer,max_length,stride)
  dataloader=DataLoader(
      dataset,
      batch_size=batch_size,
      shuffle=shuffle,
      drop_last=drop_last,
      num_workers=num_workers

  )
  return dataloader

with open("the-verdict.txt","r") as f:
  raw_text=f.read()

import torch
dataloader=create_dataloader(raw_text,1,4,1,False)
data_iter=iter(dataloader)
first_batch=next(data_iter)
print(first_batch)